<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <!-- Responsive design - adoptive to different screen sizes -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Set the webpage's title displayed in the browser's tab or title bar -->
    <title>Model Demo FastAPI</title>
    <!-- Links an external CSS stylesheet located -->
    <link rel="stylesheet" href="/static/styles.css">
    <!-- Includes the HTMX JavaScript library (v 1.6.1) from the unpkg CDN -->
    <script src="https://unpkg.com/htmx.org@1.6.1"></script>
</head>
<body>
    <div class="main-header">
        <h1>Welcome to Zhaohui Wang's ML Model Deployment Server API Demo</h1>
    </div>
    <div class="content">
        <ol>
        <h2>Environment setup</h2>
        <h3>Poetry environment</h3>
        <p>There is venv in <code>/venvs/uv-venvs/pytorch</code> that can be used directly without creating it in this directory. The instruction is in <em>README.md</em> file inside the <strong>pytorch</strong> directory. Create a new project directory and add at least the following python libraries..</p>
        <pre><code class="language-bash">
            uv add torch torchvision matplotlib seaborn 
            uv add fastapi[standard]
            uv add requests rich
        </code></pre>
        <p>First, change the directory to your project <code>/dev/pytorch-projects</code>; start a VSCode editor <code>code .</code>; you may need to activate the environment: <code>source .venv/bin/activate</code> (for my specific setting <code>source ../venvs/uv-venvs/pytorch/.venv/bin/activate</code>) after which you should expect <code>(venv-name)</code> at the beginning of the bash/zsh prompt indicating you are inside a Python environment. You can then generate synthetic data, train a model and test the FastAPI.</p>
        <p>Here are the how the files are organized in my project directory.</p>
        <pre><code class="language-bash">.
            .
            ├── README.md
            ├── data
            │   └── model_demo
            │       ├── api_logfile.log
            │       ├── data_logfile.log
            │       ├── data_tensors.pt
            │       ├── model_logfile.log
            │       ├── predictions.csv
            │       ├── predictions.npy
            │       └── predictions.txt
            ├── models
            │   └── model_demo
            │       └── demo_model_weights.pth
            ├── src
            │   └── model_demo
            │       ├── __init__.py
            │       ├── config.py
            │       ├── data_prep.py
            │       ├── fast_api.py
            │       ├── model_demo.py
            │       ├── submit_for_inference.py
            │       └── utils.py
            ├── static
            │   └── styles.css
            └── templates
                ├── batch_predict.html
                ├── main.html
                └── predict.html
        </code></pre>
        <h2>Data Preparation</h2>
        <p>If you like to execute the <code>data_prep.py</code> as a script file, follow this instruction</p>
        <pre><code class="language-bash">
            pytorchzhaohuiwang@WangFamily:/mnt/e/zhaohuiwang/dev/pytorch-projects$ python  src/model_demo/data_prep.py
            # with the following path specification in the script
            import sys
            sys.path.append('/src/model_demo')
            from utils import synthesize_data, norm
        </code></pre>
        <p>or if you want to run it as a module</p>
        <pre><code class="language-bash">
            pytorchzhaohuiwang@WangFamily:/mnt/e/zhaohuiwang/dev/pytorch-projects$ python -m src.model_demo.data_prep
            # with the alternative specification in the script
            from src.model_demo.utils import synthesize_data, norm
        </code></pre>
        <h2>Model Training</h2>
        <p>I only configured and run <code>model_demo.py</code> as a module with <code>-m</code> option.</p>
        <pre><code class="language-bash">
            pytorchzhaohuiwang@WangFamily:/mnt/e/zhaohuiwang/dev/pytorch-projects$ python -m src.model_demo.model_demo
        </code></pre>
        <p>With the following import code (compare to the <code>data_prep.py</code> above)</p>
        <pre><code class="language-python">from src.model_demo.utils import LinearRegressionModel, load_data, infer_evaluate_model
        </code></pre>
        <h2>Model Inference</h2>
        <h3>Model inference on server</h3>
        <p>To run the server from <code>pytorchzhaohuiwang@WangFamily:/mnt/e/zhaohuiwang/dev/pytorch-projects$</code></p>
        <pre><code class="language-bash">
            python -m uvicorn src.model_demo.fast_api:app --reload --port 8000
        </code></pre>
        <p>If no port process is available, To list the PID <code>lsof -i :8000</code>, to kill the process <code>kill -9 &ltpid&gt</code>. </p>
        <p>To submit test data for inference through URL <a href="http://localhost:8000/docs">http://localhost:8000/docs</a> by Swagger UI. (typical localhost IP address is 127.0.0.1, so alternatively you may through <a href="http://127.0.0.1:8000/docs">http://127.0.0.1:8000/docs</a> instead. Run <code>cat /etc/hosts</code> from terminal to confirm the IP address). To access the ReDoc-generated page displaying your API’s documentation, navigate to <a href="http://localhost:8000/redoc">http://localhost:8000/redoc</a></p>
        <p>Go to Post &gt; [Try it out] &gt; input data into &quot;Request body&quot; box &gt; [Execute]</p>

        <h3>Model inference on Localhost URL</h3>
        <p>I alse reated single data point inferene web <code>http://localhost:8000/predict</code> and bath data inference web <code>http://localhost:8000/batch_predict</code>. User can follow the instruction to input the data and <code style="color : blue">Predict</code> the outcomes.</p>

        <h3>Model inference through Python script</h3>
        <p>To submit test data for inference through Python script</p>
        <pre><code class="language-bash">
            zhaohuiwang@WangFamily:/mnt/e/zhaohuiwang/dev/pytorch-projects$ source .venv/bin/activate
            (pytorch) zhaohuiwang@WangFamily:/mnt/e/zhaohuiwang/dev/pytorch-projects$ python src/model_demo/submit_for_inference.py
        </code></pre>
        <p>To see the prediction result from <a href="http://localhost:8000/docs">http://localhost:8000/docs</a>
        <p>Alternatively, use curl to execute prediction. Here are examples (optional: <code>&&echo</code> to add a blank line)</p>
        <pre><code class="language-bash">
            curl -X POST "http://localhost:8000/predict" -H "Content-Type: application/json" -d '{"feature_X_1": 1.0, "feature_X_2": 2.0}' &&echo
            curl -X POST "http://localhost:8000/batch_predict" -H "Content-Type: application/json" -d '{"input_data": [[1.0, 2.0], [3.0, 4.0]]}' &&echo
        </code></pre>
        <h2>Localhost URL</h2>
        <table>
            <tr>
                <th>Localhost URL</th>
                <th>Description</th>
            </tr>
            <tr>
                <td><a href="http://localhost:8000/">http://localhost:8000/</a></td>
                <td>Root / main</td>
            </tr>
            <tr>
            <td><a href="http://localhost:8000/docs">http://localhost:8000/docs</a></td>
            <td>Interactive API documentation for a FastAPI application</td>
            </tr>
            <tr>
            <td><a href="http://localhost:8000/redoc">http://localhost:8000/redoc</a></td>
            <td>IAPI documentation page generated by ReDoc</td>
            </tr>
            <tr>
            <td><a href="http://localhost:8000/predict">http://localhost:8000/predict</a></td>
            <td>Single data prediction</td>
            </tr>
            <tr>
            <td><a href="http://localhost:8000/batch_predict">http://localhost:8000/batch_predict</a></td>
            <td>Batch data prediction</td>
            </tr>
        </table>
    </ol>
    </div>
    <div>
        <p> End </p>
    </div>
</body>
</html>




<!--
<h1>Hello, World!</h1>
<p>This is a <strong>bold</strong> text with some <em>italic</em> content.</p>
<ul>
    <li>Item 1</li>
    <li>Item 2</li>
</ul>
<p><a href="https://fastapi.tiangolo.com">Link to FastAPI</a></p>

-->